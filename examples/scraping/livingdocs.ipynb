{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Procedure\n",
    "\n",
    "1. Get menu items\n",
    "2. Iterate over items\n",
    "3. Retrieve content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import json\n",
    "import csv\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "LIVINGDOCS_API_KEY = os.environ.get(\"LIVINGDOCS_API_KEY\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sitemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"https://www.ch.ch/sitemap-de.xml\")\n",
    "soup = BeautifulSoup(res.content, features=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [x.text for x in soup.find_all(\"loc\")]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for url in urls:\n",
    "    tag = url.replace(\"https://www.ch.ch/de/\", \"\").split(\"/\")[0]\n",
    "    if tag:\n",
    "        tags.append(tag)\n",
    "    else:\n",
    "        tags.append(None)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from typing import Dict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Firefox options (optional: run headless)\n",
    "options = Options()\n",
    "options.headless = False\n",
    "\n",
    "# Set up the WebDriver\n",
    "#service = Service(\"/path/to/geckodriver\")\n",
    "service = None\n",
    "driver = webdriver.Firefox(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 90\n",
    "driver.get(urls[i])\n",
    "urls[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_links(soup):\n",
    "    content = []\n",
    "    for element in soup.find_all([\"p\", \"span\", \"a\"]):  # Extract paragraphs and links\n",
    "        if element.name == \"a\":\n",
    "            content.append(f'<a href=\"{element.get(\"href\")}\">{element.text}</a>')\n",
    "        else:\n",
    "            content.append(element.text)\n",
    "    return \" \".join(content)\n",
    "\n",
    "def get_faq(soup: BeautifulSoup, url: str, language: str) -> Dict:\n",
    "\n",
    "    # get questions\n",
    "    elements = soup.find_all(\"span\", attrs={\"data-v-166b6cfb\": True}, class_=\"mr-6 text-left h2\" )\n",
    "\n",
    "    questions = []\n",
    "    for element in elements:\n",
    "        element = element.text.strip()\n",
    "        if element.endswith(\"?\"):\n",
    "            questions.append(element)\n",
    "        else:\n",
    "            questions.append(None)\n",
    "\n",
    "    questions = [q for q in questions if q]\n",
    "\n",
    "    # get answers:\n",
    "    answers = []\n",
    "    elements = soup.find_all(\"div\", {\"itemprop\": \"acceptedAnswer\"})\n",
    "    for element in elements:\n",
    "        if element:\n",
    "            answers.append(element)\n",
    "        else:\n",
    "            answers.append(None)\n",
    "\n",
    "    faq_items = []\n",
    "    if len(questions) == len(answers):\n",
    "        for q, a in zip(questions, answers):\n",
    "            faq_items.append(\n",
    "                {\n",
    "                    \"text\": q,\n",
    "                    \"answer\": extract_text_with_links(a),\n",
    "                    \"url\": url,\n",
    "                    \"language\": language,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return faq_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = soup.find_all(\"span\", attrs={\"data-v-166b6cfb\": True}, class_=\"mr-6 text-left h2\" )\n",
    "\n",
    "questions = []\n",
    "for element in elements:\n",
    "    element = element.text.strip()\n",
    "    if element.endswith(\"?\"):\n",
    "        questions.append(element)\n",
    "    else:\n",
    "        questions.append(None)\n",
    "\n",
    "questions = [q for q in questions if q]\n",
    "print(len(questions))\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "elements = soup.find_all(\"div\", {\"itemprop\": \"acceptedAnswer\"})\n",
    "for element in elements:\n",
    "    if element:\n",
    "        answers.append(element)\n",
    "    else:\n",
    "        answers.append(None)\n",
    "\n",
    "answers = [a for a in answers if a]\n",
    "\n",
    "print(len(answers))\n",
    "#print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_doc(text: str, url: str, language: str, tag: str) -> Dict:\n",
    "\n",
    "    start_marker = \"Einfache Antworten zum Leben in der Schweiz\"\n",
    "    end_marker = \"Eine Dienstleistung des Bundes, der Kantone und Gemeinden\"\n",
    "\n",
    "    # Regex pattern to capture everything between the markers (non-greedy `.*?`)\n",
    "    pattern = rf\"{re.escape(start_marker)}(.*?){re.escape(end_marker)}\"\n",
    "\n",
    "    # Search for content between markers\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Extract and print result\n",
    "    if match:\n",
    "        extracted_content = match.group(1).strip()\n",
    "        return {\n",
    "            \"text\": extracted_content,\n",
    "            \"url\": url,\n",
    "            \"language\": language,\n",
    "            \"tags\": [tag],\n",
    "            \"subtopics\": None,\n",
    "            \"summary\": None,\n",
    "            \"hyq\": None,\n",
    "            \"hyq_declarative\": None,\n",
    "            \"doctype\": \"context_doc\",\n",
    "            \"organizations\": [\"BK\"],\n",
    "        }\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Firefox options (optional: run headless)\n",
    "options = Options()\n",
    "options.headless = False\n",
    "\n",
    "# Set up the WebDriver\n",
    "#service = Service(\"/path/to/geckodriver\")\n",
    "service = None\n",
    "driver = webdriver.Firefox(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"de\"\n",
    "\n",
    "faq_items = []\n",
    "rag_docs = []\n",
    "for url, tag in zip(urls, tags):\n",
    "\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "    # faq\n",
    "    faq_items.extend(get_faq(soup, url, language))\n",
    "\n",
    "    # rag\n",
    "    text = extract_text_with_links(soup)\n",
    "    rag_docs.append(get_rag_doc(text, url, language, tag))\n",
    "\n",
    "len(rag_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_docs = [doc for doc in rag_docs if doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rag_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(faq_items).to_csv(\"indexing/data/ch_ch_copilot/autocomplete/autocomplete.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rag_docs).to_csv(\"indexing/data/ch_ch_copilot/ch_ch/ch_ch.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBED DOCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_docs = []\n",
    "for doc in rag_docs:\n",
    "    text_embedding = await get_embedding(doc[\"text\"])\n",
    "    doc[\"text_embedding\"] = text_embedding\n",
    "    embed_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(embed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(embed_docs).to_csv(\"indexing/data/ch_ch_copilot/ch_ch/ch_ch.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/ch_ch_copilot/vaud/prestations_vd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df.tags.apply(lambda x: x.split(\",\"))\n",
    "unique_tags = set(sum(tags.tolist(), []))\n",
    "unique_tags = sorted([x.strip() for x in list(unique_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"documents d'identité\": \"documents-identité\",\n",
    "    \"emploi - chômage\": \"emploi-chômage\",\n",
    "    \"l'offre de mobilité à votre disposition\": \"offre-de-mobilité-à-votre-disposition\"\n",
    "}\n",
    "\n",
    "def reformat_tag(tag: str) -> str:\n",
    "    for old, new in mapping.items():\n",
    "        if tag == old:\n",
    "            tag = new\n",
    "    tag = tag.strip().replace(\" \", \"-\")\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = df.tags.apply(lambda row: [reformat_tag(tag) for tag in row.split(\",\")])\n",
    "df[\"tags\"] = new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tags\"] = df.tags.apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"organizations\"] = \"BK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indexing/data/ch_ch_copilot/vaud/prestations_vd.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k.replace(\" \", \"-\"):k.capitalize() for k in unique_tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df = pd.read_csv(\"indexing/data/ch_ch_copilot/ch_ch/ch_ch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"organizations\"] = \"BK\"\n",
    "df[\"tags\"] = df.tags.apply(lambda x: ast.literal_eval(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indexing/data/ch_ch_copilot/ch_ch/ch_ch.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---> API APPROACH (LEGACY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/menus\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "menus = response.json()\n",
    "pprint.pprint(menus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hierarchy(nodes):\n",
    "    \"\"\"\n",
    "    Recursively builds a hierarchical dictionary from a list of nodes.\n",
    "    Each node can have its own nested nodes or a documentId.\n",
    "\n",
    "    Args:\n",
    "        nodes (list): List of nodes to process.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary representing the hierarchy.\n",
    "    \"\"\"\n",
    "    hierarchy = {}\n",
    "    for node in nodes:\n",
    "        label = node.get(\"label\", \"Unknown\")  # Use a default if 'label' is missing\n",
    "        if node.get(\"nodes\"):  # Check for nested nodes\n",
    "            hierarchy[label] = build_hierarchy(node[\"nodes\"])\n",
    "        else:\n",
    "            # Gracefully handle missing 'documentId' with a default or None\n",
    "            hierarchy[label] = node.get(\"documentId\", None)\n",
    "    return hierarchy\n",
    "\n",
    "\n",
    "def parse_menus(menus):\n",
    "    \"\"\"\n",
    "    Parses the given menus list and filters by handle,\n",
    "    constructing a hierarchical dictionary for specific handles.\n",
    "\n",
    "    Args:\n",
    "        menus (list): List of menu dictionaries to process.\n",
    "\n",
    "    Returns:\n",
    "        dict: A hierarchical dictionary with parsed data.\n",
    "    \"\"\"\n",
    "    categories = {}\n",
    "    for menu in menus:\n",
    "        label = menu.get(\"label\")\n",
    "        if label in [\"chch-de\", \"chch-fr\", \"chch-it\", \"wahlen-de\", \"wahlen-fr\", \"wahlen-it\"]:\n",
    "            categories[label] = build_hierarchy(menu.get(\"nodes\", []))\n",
    "    return categories\n",
    "\n",
    "# Example usage:\n",
    "categories = parse_menus(menus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[\"chch-fr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict(d, path=None):\n",
    "    \"\"\"\n",
    "    Inverts a nested dictionary so that the innermost values become keys,\n",
    "    and the keys in the original dictionary are reversed in the nested structure.\n",
    "\n",
    "    Args:\n",
    "        d (dict): The original dictionary to invert.\n",
    "        path (list): Tracks the path of keys leading to a value.\n",
    "\n",
    "    Returns:\n",
    "        dict: The inverted dictionary.\n",
    "    \"\"\"\n",
    "    inverted = {}\n",
    "    path = path or []\n",
    "\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Recursively process nested dictionaries\n",
    "            inverted.update(invert_dict(value, path + [key]))\n",
    "        else:\n",
    "            # Use the value as the key and reverse the path\n",
    "            if value is not None:  # Skip None values\n",
    "                inverted[value] = path + [key]\n",
    "\n",
    "    return inverted\n",
    "\n",
    "inverted = invert_dict(categories)\n",
    "#pprint.pprint(inverted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get doc by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_by_id(document_id: int) -> dict:\n",
    "\n",
    "\n",
    "    # Define filters in JSON format\n",
    "    filters = json.dumps({\n",
    "        \"key\": \"documentId\",\n",
    "        \"term\": document_id\n",
    "    })\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(\n",
    "        f\"https://cms.ch.ch/api/v1/publications/search?filters={filters}\",\n",
    "        headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    "    )\n",
    "\n",
    "    # Parse and print the response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id = 5309\n",
    "doc = get_document_by_id(document_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract left components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = doc[\"content\"][0][\"containers\"][\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeftDataExtractor:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize the extractor.\n",
    "        :param data: Input data to process.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.result_list = []\n",
    "\n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Extract and process all data.\n",
    "        \"\"\"\n",
    "        for item in self.data:\n",
    "            component = item.get('component')\n",
    "            if component == 'title':\n",
    "                self._process_title(item)\n",
    "            elif component == 'lead':\n",
    "                self._process_lead(item)\n",
    "            elif component == 'infobox':\n",
    "                self._process_infobox(item)\n",
    "        return self.result_list\n",
    "\n",
    "    def _process_title(self, item):\n",
    "        \"\"\"\n",
    "        Process title components.\n",
    "        \"\"\"\n",
    "        title = item['content'].get('title', '')\n",
    "        self.result_list.append({'type': 'title', 'title': title})\n",
    "\n",
    "    def _process_lead(self, item):\n",
    "        \"\"\"\n",
    "        Process lead components.\n",
    "        \"\"\"\n",
    "        text = item['content'].get('text', '')\n",
    "        self.result_list.append({'type': 'lead', 'text': text})\n",
    "\n",
    "    def _process_infobox(self, item):\n",
    "        \"\"\"\n",
    "        Process infobox components.\n",
    "        \"\"\"\n",
    "        infobox_content = []\n",
    "        # Extract the main text content of the infobox\n",
    "        body = item.get('containers', {}).get('infobox', [])\n",
    "        for element in body:\n",
    "            if element.get('component') == 'p':\n",
    "                text = element['content'].get('text', '')\n",
    "                infobox_content.append(text)\n",
    "\n",
    "        # Extract the category ID (if exists)\n",
    "        category_id = (\n",
    "            item.get('content', {})\n",
    "            .get('category', {})\n",
    "            .get('params', {})\n",
    "            .get('category', {})\n",
    "            .get('reference', {})\n",
    "            .get('id')\n",
    "        )\n",
    "        self.result_list.append({\n",
    "            'type': 'infobox',\n",
    "            'category_id': category_id,\n",
    "            'content': infobox_content,\n",
    "        })\n",
    "\n",
    "    def format_data(self):\n",
    "        \"\"\"\n",
    "        Format extracted data into a list of unified strings by element.\n",
    "        \"\"\"\n",
    "        formatted_elements = []\n",
    "        for item in self.result_list:\n",
    "            formatted_content = []\n",
    "\n",
    "            if item['type'] == 'title':\n",
    "                formatted_content.append(f\"# {item['title']}\")\n",
    "            elif item['type'] == 'lead':\n",
    "                formatted_content.append(f\"{item['text']}\")\n",
    "            elif item['type'] == 'infobox':\n",
    "                if item['category_id']:\n",
    "                    formatted_content.append(f\"Category ID: {item['category_id']}\")\n",
    "                if item['content']:\n",
    "                    formatted_content.append(\"\\n\".join(item['content']))\n",
    "\n",
    "            # Join all content for the element and add to the list\n",
    "            formatted_elements.append(\"\\n\".join(formatted_content))\n",
    "\n",
    "        return formatted_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = LeftDataExtractor(components)\n",
    "data = extractor.extract()\n",
    "formatted_data = extractor.format_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract right components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = doc[\"content\"][0][\"containers\"][\"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "class RightDataExtractor:\n",
    "    def __init__(self, data, document_id, api_key=None, table_format='json'):\n",
    "        \"\"\"\n",
    "        Initialize the extractor.\n",
    "        :param data: Input data to process.\n",
    "        :param documentId: The ID of the current document.\n",
    "        :param api_key: API key for accessing documents.\n",
    "        :param table_format: Format for tables ('json' or 'csv').\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.documentId = str(document_id)\n",
    "        self.api_key = api_key if api_key else LIVINGDOCS_API_KEY\n",
    "        self.table_format = table_format.lower()\n",
    "        self.result_list = []\n",
    "        self.nodes = set()\n",
    "        self.edges = []\n",
    "        self.processed_documents = set()\n",
    "\n",
    "    def get_document_by_id(self, document_id):\n",
    "        \"\"\"\n",
    "        Fetch the document with the given ID.\n",
    "        \"\"\"\n",
    "        filters = json.dumps({\n",
    "            \"key\": \"documentId\",\n",
    "            \"term\": document_id\n",
    "        })\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"https://cms.ch.ch/api/v1/publications/search?filters={filters}\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"}\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                if results:\n",
    "                    return results[0]\n",
    "            else:\n",
    "                print(f\"Error fetching document {document_id}: {response.status_code}, {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception fetching document {document_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def extract(self, data=None):\n",
    "        \"\"\"\n",
    "        Extract and process all data.\n",
    "        \"\"\"\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "            self.processed_documents.add(self.documentId)\n",
    "        self._process_components(data)\n",
    "        return self.result_list\n",
    "\n",
    "    def _process_components(self, components):\n",
    "        \"\"\"\n",
    "        Process a list of components.\n",
    "        \"\"\"\n",
    "        for item in components:\n",
    "            component = item.get('component')\n",
    "            if component == 'faq-teaser':\n",
    "                self._process_faq_teaser(item)\n",
    "            elif component == 'accordion':\n",
    "                self._process_accordion(item)\n",
    "            elif component == 'faq-container':\n",
    "                self._process_faq_container(item)\n",
    "            # Add other component types if needed\n",
    "\n",
    "    def inject_url(self, text, inverted, language):\n",
    "        \"\"\"\n",
    "        Inject URLs in the text based on specific patterns.\n",
    "        :param text: Input text to process.\n",
    "        :param inverted: Dictionary for resource resolution.\n",
    "        :param language: Language for message formatting.\n",
    "        :return: Processed text with URLs replaced.\n",
    "        \"\"\"\n",
    "        def get_resource(documentId, language):\n",
    "            resource = \" -> \".join(inverted[documentId][1:])\n",
    "            return resource\n",
    "\n",
    "        # Regex to match <a> tags with the specific href pattern and text between the tags\n",
    "        pattern = r'<a[^>]*href=\"https://www\\.ch\\.ch/(\\d+)\"[^>]*>([^<]+)</a>'\n",
    "\n",
    "        def replace_match(match):\n",
    "            document_id = match.group(1)\n",
    "            link_text = match.group(2).strip()\n",
    "            if document_id in inverted and link_text:  # Ensure document ID exists and text is non-empty\n",
    "                return get_resource(document_id, language)\n",
    "            return match.group(0)  # Leave the original tag if conditions are not met\n",
    "\n",
    "        # Replace matches in the input text\n",
    "        return re.sub(pattern, replace_match, text)\n",
    "\n",
    "    def _process_faq_teaser(self, item):\n",
    "        \"\"\"\n",
    "        Process faq-teaser components.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            document_id = item['content']['faq']['params']['teaser']['reference']['id']\n",
    "            document_id = str(document_id)\n",
    "            # Add edge to knowledge graph\n",
    "            self._add_edge(self.documentId, document_id)\n",
    "            if document_id in self.processed_documents:\n",
    "                return  # Avoid processing the same document multiple times\n",
    "            # Fetch the referenced document\n",
    "            document_data = self.get_document_by_id(document_id)\n",
    "            if document_data:\n",
    "                self.processed_documents.add(document_id)\n",
    "                # Process the content of the fetched document\n",
    "                self._process_components(document_data.get('content', []))\n",
    "            else:\n",
    "                # If unable to fetch, store the reference\n",
    "                self.result_list.append({'type': 'faq-teaser', 'documentId': document_id})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing faq-teaser: {e}\")\n",
    "            pass  # Handle errors as needed\n",
    "\n",
    "    def _process_faq_container(self, item):\n",
    "        \"\"\"\n",
    "        Process faq-container components.\n",
    "        \"\"\"\n",
    "        question = item['content'].get('question', '')\n",
    "        content_list = self._process_body(item.get('containers', {}).get('body', []))\n",
    "        self.result_list.append({'type': 'faq-container', 'question': question, 'content': content_list})\n",
    "\n",
    "    def _process_accordion(self, item):\n",
    "        \"\"\"\n",
    "        Process accordion components.\n",
    "        \"\"\"\n",
    "        title = item['content'].get('title', '')\n",
    "        content_list = self._process_body(item.get('containers', {}).get('body', []))\n",
    "        self.result_list.append({'type': 'accordion', 'title': title, 'content': content_list})\n",
    "\n",
    "    def _process_body(self, body):\n",
    "        \"\"\"\n",
    "        Process the body of components like accordion or faq-container.\n",
    "        \"\"\"\n",
    "        content_list = []\n",
    "\n",
    "        for element in body:\n",
    "            elem_component = element.get('component')\n",
    "            if elem_component == 'subtitle':\n",
    "                subtitle_title = element['content'].get('title', '')\n",
    "                content_list.append({'type': 'subtitle', 'title': subtitle_title})\n",
    "            elif elem_component == 'p':\n",
    "                text = element['content'].get('text', '')\n",
    "                content_list.append({'type': 'p', 'text': text})\n",
    "                self._extract_urls_from_text(text)\n",
    "            elif elem_component == 'list':\n",
    "                list_content = self._process_list(element)\n",
    "                content_list.append(list_content)\n",
    "                for item in list_content['items']:\n",
    "                    self._extract_urls_from_text(item)\n",
    "            elif elem_component == 'table':\n",
    "                table_content = self._process_table(element)\n",
    "                content_list.append(table_content)\n",
    "                # Extract URLs from table content\n",
    "                self._extract_urls_from_table(table_content)\n",
    "            elif elem_component == 'faq-teaser':\n",
    "                self._process_faq_teaser(element)\n",
    "            # Handle other components as needed\n",
    "\n",
    "        return content_list\n",
    "\n",
    "    def _process_list(self, element):\n",
    "        \"\"\"\n",
    "        Process list components.\n",
    "        \"\"\"\n",
    "        list_items = element.get('containers', {}).get('list', [])\n",
    "        items = [item.get('content', {}).get('text', '') for item in list_items]\n",
    "        return {'type': 'list', 'items': items}\n",
    "\n",
    "    def _process_table(self, element):\n",
    "        \"\"\"\n",
    "        Process table components and return in the specified format.\n",
    "        \"\"\"\n",
    "        containers = element.get('containers', {})\n",
    "        headers = []\n",
    "\n",
    "        # Extract headers\n",
    "        header_rows = containers.get('header', [])\n",
    "        for header_row in header_rows:\n",
    "            cells = header_row.get('containers', {}).get('header-row', [])\n",
    "            for cell in cells:\n",
    "                header_text = self._extract_text_from_containers(cell, 'header-cell')\n",
    "                headers.append(header_text)\n",
    "\n",
    "        # Extract rows\n",
    "        rows = []\n",
    "        body_rows = containers.get('body', [])\n",
    "        for body_row in body_rows:\n",
    "            row_data = {}\n",
    "            cells = body_row.get('containers', {}).get('body-row', [])\n",
    "            for idx, cell in enumerate(cells):\n",
    "                cell_text = self._extract_text_from_containers(cell, 'body-cell')\n",
    "                if idx < len(headers):\n",
    "                    row_data[headers[idx]] = cell_text\n",
    "                else:\n",
    "                    row_data[f\"Column_{idx + 1}\"] = cell_text\n",
    "            rows.append(row_data)\n",
    "\n",
    "        if self.table_format == 'csv':\n",
    "            return {'type': 'table', 'data': self._table_to_csv(headers, rows)}\n",
    "        return {'type': 'table', 'data': rows}\n",
    "\n",
    "    def _table_to_csv(self, headers, rows):\n",
    "        \"\"\"\n",
    "        Convert table data to CSV format.\n",
    "        \"\"\"\n",
    "        from io import StringIO\n",
    "        import csv\n",
    "\n",
    "        output = StringIO()\n",
    "        writer = csv.DictWriter(output, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        for row in rows:\n",
    "            writer.writerow(row)\n",
    "        return output.getvalue().strip()\n",
    "\n",
    "    def _extract_text_from_containers(self, container, cell_type):\n",
    "        \"\"\"\n",
    "        Helper method to extract text from nested containers.\n",
    "        \"\"\"\n",
    "        cell_text = ''\n",
    "        cell_contents = container.get('containers', {}).get(cell_type, [])\n",
    "        for content in cell_contents:\n",
    "            if content.get('component') == 'p':\n",
    "                text = content.get('content', {}).get('text', '')\n",
    "                cell_text += text\n",
    "                self._extract_urls_from_text(text)\n",
    "        return cell_text\n",
    "\n",
    "    def _extract_urls_from_text(self, text):\n",
    "        \"\"\"\n",
    "        Extract URLs from the given text and update nodes and edges.\n",
    "        \"\"\"\n",
    "        # Regex to find all href attributes in <a> tags\n",
    "        hrefs = re.findall(r'<a[^>]*href=\"([^\"]+)\"[^>]*>(.*?)</a>', text)\n",
    "\n",
    "        internal_pattern = re.compile(r'https://www\\.ch\\.ch/(\\d+)')\n",
    "\n",
    "        for href, link_text in hrefs:\n",
    "            if href.strip():\n",
    "                internal_match = internal_pattern.match(href)\n",
    "                if internal_match:\n",
    "                    # Internal URL\n",
    "                    target_document_id = internal_match.group(1)\n",
    "                    self._add_edge(self.documentId, target_document_id)\n",
    "                else:\n",
    "                    # External URL\n",
    "                    self._add_edge(self.documentId, href)\n",
    "\n",
    "    def _extract_urls_from_table(self, table_content):\n",
    "        \"\"\"\n",
    "        Extract URLs from table data.\n",
    "        \"\"\"\n",
    "        if self.table_format == 'csv':\n",
    "            # Parse CSV data\n",
    "            import csv\n",
    "            from io import StringIO\n",
    "\n",
    "            csv_data = StringIO(table_content['data'])\n",
    "            reader = csv.DictReader(csv_data)\n",
    "            for row in reader:\n",
    "                for cell in row.values():\n",
    "                    self._extract_urls_from_text(cell)\n",
    "        else:\n",
    "            # JSON format\n",
    "            for row in table_content['data']:\n",
    "                for cell in row.values():\n",
    "                    self._extract_urls_from_text(cell)\n",
    "\n",
    "    def _add_edge(self, source, target):\n",
    "        \"\"\"\n",
    "        Add an edge to the knowledge graph.\n",
    "        \"\"\"\n",
    "        self.nodes.add(str(source))\n",
    "        self.nodes.add(str(target))\n",
    "        self.edges.append((str(source), str(target)))\n",
    "\n",
    "    def build_knowledge_graph(self):\n",
    "        \"\"\"\n",
    "        Build and return the knowledge graph representation.\n",
    "        \"\"\"\n",
    "        graph = {\n",
    "            'nodes': list(self.nodes),\n",
    "            'edges': [{'source': s, 'target': t} for s, t in self.edges]\n",
    "        }\n",
    "        return graph\n",
    "\n",
    "    def format_data(self):\n",
    "        \"\"\"\n",
    "        Format extracted data into a list of unified strings by element.\n",
    "        \"\"\"\n",
    "        formatted_elements = []\n",
    "        for item in self.result_list:\n",
    "            formatted_content = []\n",
    "\n",
    "            # Format Accordion\n",
    "            if item['type'] == 'accordion':\n",
    "                formatted_content.append(f\"# {item['title']}\")\n",
    "                formatted_content.extend(self._format_content_list(item.get('content', [])))\n",
    "\n",
    "            # Format FAQ Container\n",
    "            elif item['type'] == 'faq-container':\n",
    "                formatted_content.append(f\"Question: {item['question']}\")\n",
    "                formatted_content.extend(self._format_content_list(item.get('content', [])))\n",
    "\n",
    "            # Handle other components as needed\n",
    "            # Note: faq-teaser content is processed and added via recursive calls\n",
    "\n",
    "            # Join all content for the element and add to the list\n",
    "            formatted_elements.append(\"\\n\".join(formatted_content))\n",
    "\n",
    "        return formatted_elements\n",
    "\n",
    "    def _format_content_list(self, content_list):\n",
    "        \"\"\"\n",
    "        Helper method to format content list for output.\n",
    "        \"\"\"\n",
    "        formatted_content = []\n",
    "        for content in content_list:\n",
    "            if content['type'] == 'subtitle':\n",
    "                formatted_content.append(f\"## {content['title']}\")\n",
    "            elif content['type'] == 'p':\n",
    "                formatted_content.append(content['text'])\n",
    "            elif content['type'] == 'list':\n",
    "                formatted_content.append(\"\\n\".join([f\"- {i}\" for i in content['items']]))\n",
    "            elif content['type'] == 'table':\n",
    "                table_data = content['data']\n",
    "                if self.table_format == 'csv':\n",
    "                    formatted_content.append(f\"\\n{table_data}\")\n",
    "                else:  # JSON\n",
    "                    formatted_content.append(json.dumps(table_data, indent=2))\n",
    "        return formatted_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = RightDataExtractor(components, document_id=document_id)\n",
    "data = extractor.extract()\n",
    "knowledge_graph = extractor.build_knowledge_graph()\n",
    "\n",
    "# Print the knowledge graph in JSON format\n",
    "print(json.dumps(knowledge_graph, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = RightDataExtractor(components, document_id, table_format='csv')\n",
    "data = extractor.extract()\n",
    "formatted_data = extractor.format_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formatted_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on all document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id in inverted.keys():\n",
    "    print(f\"DOC ID: {doc_id}\")\n",
    "    extractor = RightDataExtractor(components, doc_id, table_format='csv')\n",
    "    data = extractor.extract()\n",
    "    formatted_data = extractor.format_data()\n",
    "\n",
    "    for item in formatted_data:\n",
    "        print(item)\n",
    "        print(\"------\")\n",
    "    print(\"---------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/project\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/document-lists\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/document-lists/54172\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/categories/faq-teaser\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "res = response.json()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/publications/search?component=faq-teaser?limit=1\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "res = response.json()\n",
    "pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/publications/search?limit=100\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "res = response.json()\n",
    "pprint.pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"systemdata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"content\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"content\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"content\"][0][\"containers\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"content\"][0][\"containers\"][\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[4][\"content\"][0][\"containers\"][\"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_BASE_URL = \"https://cms.ch.ch/api/v1\"\n",
    "\n",
    "# Example data structure with items\n",
    "items = [\n",
    "    {\n",
    "        'component': 'faq-teaser',\n",
    "        'identifier': 'p:34:34.faq-teaser',\n",
    "        'id': 'doc-1iaq8v15f0',\n",
    "        'content': {\n",
    "            'faq': {\n",
    "                'service': 'faq-teaser',\n",
    "                'params': {\n",
    "                    'teaser': {\n",
    "                        '$ref': 'document',\n",
    "                        'reference': {'id': '10328'}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'component': 'accordion',\n",
    "        'identifier': 'p:34:34.accordion',\n",
    "        'id': 'doc-1iaq8liqi0',\n",
    "        'content': {'title': 'Voyager avec des enfants'}\n",
    "    }\n",
    "]\n",
    "\n",
    "def fetch_document_by_id(doc_id):\n",
    "    # Make a GET request to fetch the document content\n",
    "    url = f\"{API_BASE_URL}/publications/{doc_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching document {doc_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Extract and process faq-teaser items\n",
    "for item in items:\n",
    "    if item['component'] == 'faq-teaser':\n",
    "        ref_id = item['content']['faq']['params']['teaser']['reference']['id']\n",
    "        print(f\"Fetching content for reference ID: {ref_id}\")\n",
    "        document = fetch_document_by_id(ref_id)\n",
    "        if document:\n",
    "            print(f\"Content for {ref_id}: {document}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{API_BASE_URL}/publications/{5810}\"\n",
    "headers = {\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/sitemaps/index\",\n",
    "    params={\"baseUrl\": \"https://www.ch.ch\"},\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "res = response.json()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://cms.ch.ch/api/v1/documents/latestPublications\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "res = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://livingdocs-ch-ch-prod/api/v1/project\",\n",
    "    headers={\"Authorization\": f\"Bearer {LIVINGDOCS_API_KEY}\"}\n",
    ")\n",
    "res = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
