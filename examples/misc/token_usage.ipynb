{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20417fd9-349e-4078-81ac-eda27f3cc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langfuse import Langfuse\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from config.base_config import rag_config\n",
    "from prompts.rag import RAG_SYSTEM_PROMPT_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3381d269-cb5c-4faf-83a7-cef9a7bfc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "LANGFUSE_SECRET_KEY = os.environ.get(\"LANGFUSE_SECRET_KEY\", None)\n",
    "LANGFUSE_PUBLIC_KEY = os.environ.get(\"LANGFUSE_PUBLIC_KEY\", None)\n",
    "LANGFUSE_HOST = \"http://localhost:3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d813dc80-6119-49e6-bf60-043a313f756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse = Langfuse(\n",
    "  secret_key=LANGFUSE_SECRET_KEY,\n",
    "  public_key=LANGFUSE_PUBLIC_KEY,\n",
    "  host=LANGFUSE_HOST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d18115f-5938-4bfa-8561-7026b2ebac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736c30b2-0401-4846-bed0-d4c0acfa7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# get cached input tokens\n",
    "# system prompt for rag/retrievers/etc. depending on user selection\n",
    "\n",
    "# model providers\n",
    "class ModelProvider(Enum):\n",
    "    OPENAI = \"openai\"\n",
    "    AZUREOPENAI = \"azure_openai\"\n",
    "    ANTHROPIC = \"anthropic\"\n",
    "    GROQ = \"groq\"\n",
    "    GEMINI = \"gemini\"\n",
    "    MISTRAL = \"mistral\"\n",
    "\n",
    "# get output tokens\n",
    "class ModelPricingService:\n",
    "\n",
    "    _PRICING = {\n",
    "        ModelProvider.OPENAI: {\n",
    "            \"IN\": 0.15 / 1_000_0000,\n",
    "            \"IN_CACHED\": 0.075 / 1_000_0000,\n",
    "            \"OUT\": 0.6 / 1_000_0000,\n",
    "        },\n",
    "        ModelProvider.AZUREOPENAI: {\n",
    "            \"IN\": 0.15 / 1_000_0000,\n",
    "            \"IN_CACHED\": 0.075 / 1_000_0000,\n",
    "            \"OUT\": 0.6 / 1_000_0000,\n",
    "        },\n",
    "        ModelProvider.ANTHROPIC: {\n",
    "            \"IN\": 0.15 / 1_000_0000,\n",
    "            \"IN_CACHED\": 0.075 / 1_000_0000,\n",
    "            \"OUT\": 0.6 / 1_000_0000,\n",
    "        },\n",
    "        ModelProvider.GROQ: {\n",
    "            \"IN\": 0.15 / 1_000_0000,\n",
    "            \"IN_CACHED\": 0.075 / 1_000_0000,\n",
    "            \"OUT\": 0.6 / 1_000_0000,\n",
    "        },\n",
    "        ModelProvider.GEMINI: {\n",
    "            \"IN\": 0.15 / 1_000_0000,\n",
    "            \"IN_CACHED\": 0.075 / 1_000_0000,\n",
    "            \"OUT\": 0.6 / 1_000_0000,\n",
    "        },\n",
    "        ModelProvider.MISTRAL: {\n",
    "            \"IN\": 0.15 / 1_000_0000,\n",
    "            \"IN_CACHED\": 0.075 / 1_000_0000,\n",
    "            \"OUT\": 0.6 / 1_000_0000,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_input_cost(cls, n_tokens: int, model_provider: ModelProvider, **kwargs) -> float:\n",
    "        input_cost = cls._PRICING[model_provider].get(\"IN\") * n_tokens\n",
    "        return input_cost\n",
    "\n",
    "    @classmethod\n",
    "    def get_input_cached_cost(cls, n_tokens: int, model_provider: ModelProvider, **kwargs) -> float:\n",
    "        input_cost = cls._PRICING[model_provider].get(\"IN_CACHED\") * n_tokens\n",
    "        return input_cost\n",
    "\n",
    "    @classmethod\n",
    "    def get_output_cost(cls, n_tokens: int, model_provider: ModelProvider, **kwargs) -> float:\n",
    "        input_cost = cls._PRICING[model_provider].get(\"OUT\") * n_tokens\n",
    "        return input_cost\n",
    "\n",
    "    @classmethod\n",
    "    def get_total_cost(cls, n_input_tokens: int, n_input_cached_tokens: int, n_output_tokens: int, model_provider: ModelProvider, **kwargs) -> float:\n",
    "        n_input_tokens_cost = cls.get_input_cost(n_input_tokens, model_provider)\n",
    "        n_input_cached_tokens_cost = cls.get_input_cached_cost(n_input_cached_tokens, model_provider)\n",
    "        n_output_tokens_cost = cls.get_output_cost(n_output_tokens, model_provider)\n",
    "\n",
    "        cost = {\n",
    "            \"n_input_tokens_cost\": n_input_tokens_cost,\n",
    "            \"n_input_cached_tokens_cost\": n_input_cached_tokens_cost,\n",
    "            \"n_output_tokens_cost\": n_output_tokens_cost,\n",
    "            \"total_cost\": n_input_tokens_cost + n_input_cached_tokens_cost + n_output_tokens_cost\n",
    "        }\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a4d063-83ce-4d14-a886-cc1c0b6f52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def longest_common_prefix(str1, str2):\n",
    "    # Use itertools to find the longest common prefix\n",
    "    return ''.join(x[0] for x in itertools.takewhile(lambda x: x[0] == x[1], zip(str1, str2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde46b4-5288-4878-beac-7db6024f1175",
   "metadata": {},
   "source": [
    "# Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420e121-5884-454e-adb8-e7e2437f5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = langfuse.fetch_traces().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b035d92-2a83-4e17-8915-6943e1ffa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = langfuse.fetch_observations(name=\"MessageBuilder_build_chat_prompt\")\n",
    "len(messages.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d419112d-4ed6-43cc-aef7-3538ba2be2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_tokens(messages):\n",
    "    for message in messages.data[0].output:\n",
    "        if message[\"role\"] == \"system\":\n",
    "\n",
    "            # find longest commong prefix\n",
    "            prefix = longest_common_prefix(message[\"content\"], RAG_SYSTEM_PROMPT_FR)\n",
    "\n",
    "            # get input cached tokens\n",
    "            n_input_cached_tokens = len(tokenizer.encode(prefix))\n",
    "\n",
    "            # get input tokens\n",
    "            input_tokens = message[\"content\"].replace(prefix, \"\")\n",
    "            n_input_tokens = len(tokenizer.encode(input_tokens))\n",
    "\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            # get query input tokens\n",
    "            n_query_input_tokens = len(tokenizer.encode(message[\"content\"]))\n",
    "\n",
    "\n",
    "    n_input_tokens = {\n",
    "        \"n_input_cached_tokens\": n_input_cached_tokens,\n",
    "        \"n_input_tokens\": n_input_tokens + n_query_input_tokens,\n",
    "    }\n",
    "\n",
    "    return n_input_tokens\n",
    "\n",
    "input_tokens = get_input_tokens(messages)\n",
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a354c3f2-67b9-4b2a-9964-8fb5525bc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stream = langfuse.fetch_observations(name=\"openai_output_stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6d2b5-00c7-4593-98b5-cf22c7fbab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_tokens(output_stream):\n",
    "    output_tokens = [tok for tok in output_stream.data[0].output if tok[\"content\"]]\n",
    "    n_output_tokens = len(output_tokens)\n",
    "\n",
    "    return {\"n_output_tokens\": n_output_tokens}\n",
    "\n",
    "output_tokens = get_output_tokens(output_stream)\n",
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d0047-9212-4825-9492-ca742e66eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelPricingService.get_total_cost(\n",
    "    n_input_tokens=input_tokens[\"n_input_tokens\"],\n",
    "    n_input_cached_tokens=input_tokens[\"n_input_cached_tokens\"],\n",
    "    n_output_tokens=output_tokens[\"n_output_tokens\"],\n",
    "    model_provider=ModelProvider.OPENAI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4953a50-9a55-4e7c-addf-c409710836ce",
   "metadata": {},
   "source": [
    "# Get cached input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f48615-5d1b-4369-a000-08119d2bb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in input_tokens.data[0].output:\n",
    "    if message[\"role\"] == \"system\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cfc6d-75e0-423a-b6d2-a2d80119064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached input\n",
    "cached_input = longest_common_prefix(message[\"content\"], RAG_SYSTEM_PROMPT_FR)\n",
    "cached_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd1059-f3d0-43b8-802a-09a26d3e01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_cached_tokens = len(tokenizer.encode(cached_input))\n",
    "n_input_cached_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54459d23-ba74-46c4-a131-62445b420e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-cached input\n",
    "non_cached_input = message[\"content\"].replace(prefix, \"\")\n",
    "non_cached_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51047259-5030-45f0-bebc-fcbca7898734",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in input_tokens.data[0].output:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8b5fc-355b-4526-a251-9bf9f27438a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_query_input_tokens = len(tokenizer.encode(message[\"content\"]))\n",
    "n_query_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a9346-4be2-4b5e-8ee3-2576d141dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_tokens = len(tokenizer.encode(non_cached_input)) + n_query_input_tokens\n",
    "n_input_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843be7c4-87d4-40cf-af36-b930d59da2b6",
   "metadata": {},
   "source": [
    "# Get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6e8206-1d70-4eb5-af9f-612797830129",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = langfuse.fetch_traces().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e00f48-aa96-4de2-a69f-bf40daf4225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stream = langfuse.fetch_observations(name=\"openai_output_stream\")\n",
    "output_tokens = [tok for tok in output_stream.data[0].output if tok[\"content\"]]\n",
    "n_output_tokens = len(output_tokens)\n",
    "n_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f004b25-8b37-4bac-9dc3-c4ef8c576335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799632c-c583-452b-b9ae-f903799015ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa76375-8408-4c8b-86c5-69b1b99b9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse.fetch_observations(name=\"openai_output_stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9dc4d-3074-4cc6-8ea4-b588ae4b90ac",
   "metadata": {},
   "source": [
    "# Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5aeb8-da43-4214-9c31-bb494949e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelPricingService.get_total_cost(\n",
    "    n_input_tokens=n_input_tokens,\n",
    "    n_input_cached_tokens=n_input_cached_tokens,\n",
    "    n_output_tokens=n_output_tokens,\n",
    "    model_provider=ModelProvider.OPENAI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd803942-88ac-4685-865c-a96658d4cc50",
   "metadata": {},
   "source": [
    "# Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c202f-ae35-4550-9f4f-172672686f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = langfuse.fetch_observations(name=\"retrieve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664eee72-572e-4278-a6c0-8604c55ca426",
   "metadata": {},
   "source": [
    "# Source validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb7908-205f-4ef8-bfd4-dc65e2a25626",
   "metadata": {},
   "source": [
    "# Topic check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5adf23-cd9f-4a16-85a7-ac3b093c300c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d4c02-8a81-443e-af84-02057c1c415a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5331f23-6879-4d50-9b05-f0f7a2f4e4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146319fe-63a1-4d54-92c3-6f026140e08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b0be6-a9f2-4ec5-aa7c-dcb24146ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b99e5a-951d-4314-be3d-18b1851952eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing = {\n",
    "    \"gpt-4o\": {\n",
    "        \"input\": 5,\n",
    "        \"output\": 15\n",
    "    },\n",
    "    \"gpt-4o-2024-08-06\": {\n",
    "        \"input\": 2.5,\n",
    "        \"output\": 10\n",
    "    },\n",
    "    \"gpt-4o-2024-05-13\": {\n",
    "        \"input\": 5,\n",
    "        \"output\": 15\n",
    "    },\n",
    "    \"gpt-4o-mini\": {\n",
    "        \"input\": 0.15,\n",
    "        \"output\": 0.6\n",
    "    },\n",
    "    \"gpt-4o-mini-2024-07-18\": {\n",
    "        \"input\": 0.15,\n",
    "        \"output\": 0.6\n",
    "    },\n",
    "    \"chatgpt-4o-latest\": {\n",
    "        \"input\": 5.00,\n",
    "        \"output\": 15.00\n",
    "    },\n",
    "    \"gpt-4-turbo\": {\n",
    "        \"input\": 10.00,\n",
    "        \"output\": 30.00\n",
    "    },\n",
    "    \"gpt-4-turbo-2024-04-09\": {\n",
    "        \"input\": 10.00,\n",
    "        \"output\": 30.00\n",
    "    },\n",
    "    \"gpt-4\": {\n",
    "        \"input\": 30.00,\n",
    "        \"output\": 60.00\n",
    "    },\n",
    "    \"gpt-4-32k\": {\n",
    "        \"input\": 60.00,\n",
    "        \"output\": 120.00\n",
    "    },\n",
    "    \"gpt-4-0125-preview\": {\n",
    "        \"input\": 10.00,\n",
    "        \"output\": 30.00\n",
    "    },\n",
    "    \"gpt-4-1106-preview\": {\n",
    "        \"input\": 10.00,\n",
    "        \"output\": 30.00\n",
    "    },\n",
    "    \"gpt-4-vision-preview\": {\n",
    "        \"input\": 10.00,\n",
    "        \"output\": 30.00\n",
    "    },\n",
    "    \"gpt-3.5-turbo-0125\": {\n",
    "        \"input\": 0.50,\n",
    "        \"output\": 1.50\n",
    "    },\n",
    "    \"gpt-3.5-turbo-instruct\": {\n",
    "        \"input\": 1.50,\n",
    "        \"output\": 2.00\n",
    "    },\n",
    "    \"gpt-3.5-turbo-1106\": {\n",
    "        \"input\": 1.00,\n",
    "        \"output\": 2.00\n",
    "    },\n",
    "    \"gpt-3.5-turbo-0613\": {\n",
    "        \"input\": 1.50,\n",
    "        \"output\": 2.00\n",
    "    },\n",
    "    \"gpt-3.5-turbo-16k-0613\": {\n",
    "        \"input\": 3.00,\n",
    "        \"output\": 4.00\n",
    "    },\n",
    "    \"gpt-3.5-turbo-0301\": {\n",
    "        \"input\": 1.50,\n",
    "        \"output\": 2.00\n",
    "    }\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926e237-42a8-4ace-baa1-11433ef3b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rag_config[\"llm\"][\"model\"]\n",
    "\n",
    "if model in [\"gpt-4o\", \"gpt-4o-2024-05-13\", \"gpt-4o-2024-08-06\", \"chatgpt-4o-latest\", \"gpt-4o-mini\", \"gpt-4o-mini-2024-07-18\"]:\n",
    "    encoding = \"o200k_base\"\n",
    "elif model in [\"gpt-4-turbo\", \"gpt-4-turbo-2024-04-09\", \"gpt-4-turbo-preview\", \"gpt-4-0125-preview\", \"gpt-4-1106-preview\", \"gpt-4\",\n",
    "               \"gpt-4-0613\", \"gpt-4-0314\", \"gpt-3.5-turbo-0125\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo-instruct\"]:\n",
    "    encoding = \"cl100k_base\"\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(encoding)\n",
    "\n",
    "def get_cost(tokenizer, input: List[str], output: List[str], pricing: Dict, model: str):\n",
    "\n",
    "    n_input_toks = len(tokenizer.encode(input))\n",
    "    n_output_toks = len(tokenizer.encode(output))\n",
    "    input_cost = n_input_toks * pricing[model][\"input\"] / 1_000_000\n",
    "    output_cost = n_input_toks * pricing[model][\"output\"] / 1_000_000\n",
    "\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92a254-af6a-4348-aa99-13c7c3df41f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba610fe6-a526-45a8-b826-1f05c8fc8d49",
   "metadata": {},
   "source": [
    "### Get traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0530a-ef2a-4f44-a453-4e33ebf2523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = langfuse.fetch_traces().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7ce7a-3b7a-4129-9b81-c60087bbcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671b253-d170-46ca-b083-c22355e25801",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_data = []\n",
    "\n",
    "for trace in traces:\n",
    "\n",
    "    _input = trace.input[\"kwargs\"][\"request\"][\"query\"]\n",
    "    output = \"\".join(trace.output) if trace.output else \"\"\n",
    "    trace_data.append(\n",
    "        {\n",
    "            \"id\": trace.id,\n",
    "            \"timestamp\": trace.timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"latency\": trace.latency,\n",
    "            \"cost\": get_cost(tokenizer=tokenizer,\n",
    "                       _input=_input,\n",
    "                       output=output,\n",
    "                       pricing=pricing,\n",
    "                       model=model),\n",
    "            \"input\": _input,\n",
    "            \"output\": output\n",
    "        }\n",
    "    )\n",
    "\n",
    "trace_data_df = pd.DataFrame(trace_data)\n",
    "trace_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc0a68-83ab-403f-acf7-5a80c585cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_data_df.cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427b86f-0090-430d-a025-7a0122e1e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9b074-0922-4d27-8ef7-a2ad5eed0211",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac3d91-3343-46a6-9645-666ae46a2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = langfuse.fetch_observations(name=\"retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742cd10-258a-4c70-b269-3946f59aca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {obs.trace_id: obs.output for obs in observations.data}\n",
    "trace_data_df[\"retrieval\"] = trace_data_df[\"id\"].map(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c84f4-27e0-45f5-82b3-9a448cf1bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bbba7-bd57-4f63-96ab-7647748345bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7dd9ca-326b-4ed3-b214-04e696d99654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adeb0f-9a21-4393-ae96-b41360582afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_copilot",
   "language": "python",
   "name": "venv_copilot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
