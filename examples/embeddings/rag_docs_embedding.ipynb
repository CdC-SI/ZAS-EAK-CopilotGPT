{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf59dee-6b88-4675-8462-428df38b40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c998dad-d04a-445b-abc9-14edcfe45a33",
   "metadata": {},
   "source": [
    "# AHV-IV MEMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897bfb7-f5ce-4a04-9a21-048ba8bfc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/to_upsert/ahv_iv_memento/ahv_iv_de_fr_it_tags_subtopics_llm_EMBED.csv\")\n",
    "df.rename(columns={\"text_summary\": \"summary_embedding\"}, inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dab12d-245b-4203-8250-8899b9f9acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42903fb4-9192-4072-bb17-28c504049e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indexing/data/to_upsert/ahv_iv_memento/ahv_iv_de_fr_it_tags_subtopics_llm_EMBED.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1723e-3f8d-46c2-88b9-f61d9d7536ff",
   "metadata": {},
   "source": [
    "# EAK - AHV LERNBAUSTEIN 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8985ee-5ebd-46d0-8bb0-257b727c2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/to_upsert/AHV_Lernbaustein_2024/AHV_Lernbaustein_2024_tags_llm_EMBED.csv\")\n",
    "df.rename(columns={\"text_summary\": \"summary_embedding\"}, inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a12746-aa1f-47b3-aea0-99c6d4d3341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead61368-947d-4c89-a3d3-a01a0c84f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indexing/data/to_upsert/AHV_Lernbaustein_2024/AHV_Lernbaustein_2024_tags_llm_EMBED.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fdd733-1f07-4425-b008-916e830897e2",
   "metadata": {},
   "source": [
    "# EAK PRAXISLEITFADEN 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83cb7e-19c7-44ac-8fa1-4353929fd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/to_upsert/Guide_Pratique_CAF_CFC/guide_pratique_caf_cfc_de_tags_llm.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f0b7e-a342-4f9c-b43b-e8f22fb794b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24394e9c-2e02-46ea-aab8-1d402a5882d9",
   "metadata": {},
   "source": [
    "# AKIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ae79d-ed2b-4a64-b45a-e3b9b491dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/zas_eak_copilot/akis/akis_EMBED_2.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9f42b-18ca-4069-8c50-08e6c47774f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87487a1e-77d5-448e-85dc-af0466917bfc",
   "metadata": {},
   "source": [
    "# EAK ADMIN CH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda3a75-e382-4da7-ac4a-2a06ab24e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/to_upsert/eak_admin_ch/eak_admin_ch_de_fr_tags_NEW.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a164a0-e106-4296-acb8-a9e283db197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6bcb18-f53d-4908-b1da-8b3704de8f34",
   "metadata": {},
   "source": [
    "# FEDLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c96cbfc-9aae-4345-b9d1-c8257ffd54cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../preprocessing/data/output/fedlex.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c54ba-203a-47e3-a60b-9a2ba82a3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb82b13",
   "metadata": {},
   "source": [
    "# OFAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b80d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../preprocessing/data/output/ofas.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52792a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce61f5-786a-4ce8-af52-be674ea0fb3a",
   "metadata": {},
   "source": [
    "# AUTOCOMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7e724-d379-4716-86f1-3c3e8deb09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/to_upsert/autocomplete/question.csv\")\n",
    "\n",
    "df[\"text_embedding\"] = None\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cc471-4e0f-43f9-a742-0b005c3f1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae7238-663b-41d3-9b5f-49d8a555e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm.tqdm(df.iterrows()):\n",
    "\n",
    "    embeddings = await get_embedding([row.text])\n",
    "\n",
    "    df.loc[i, \"text_embedding\"] = str(embeddings[0].embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddb8c3-9e08-4f77-a175-3b14703e5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eebb48-b8fd-4a65-ab57-ec98b3ac4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indexing/data/to_upsert/autocomplete/question_EMBED.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f834043-ddd3-4376-a9d6-5b551869b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"indexing/data/to_upsert/autocomplete/eak_admin_ch_de_fr_tags_EMBED.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0b559-7c28-4ba4-871d-c0507c11e01e",
   "metadata": {},
   "source": [
    "# EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908b1373-c25c-4744-8a27-06e8c31c99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT_TOKENS = 8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f4c1bf0-395b-4388-9420-4abf4092b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55ff663-df86-4b6d-af10-95ffcf660d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deyan\\cdc\\ZAS-EAK-CopilotGPT\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'src', 'copilot', 'app')))\n",
    "\n",
    "# Now you can import the function\n",
    "from utils.embedding import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd105a5-0486-426b-8185-70b0e61b61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_embedding\"] = None\n",
    "df[\"tags_embedding\"] = None\n",
    "df[\"subtopics_embedding\"] = None\n",
    "df[\"summary_embedding\"] = None\n",
    "df[\"hyq_embedding\"] = None\n",
    "df[\"hyq_declarative_embedding\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021529bd",
   "metadata": {},
   "source": [
    "## WITHOUT CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ca15d-f1c6-49f5-816d-e5496edefbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm.tqdm(df.iterrows()):\n",
    "\n",
    "    try:\n",
    "        tokens = tokenizer.encode(row.text)\n",
    "        if len(tokens) > MAX_INPUT_TOKENS:\n",
    "            truncated_text = tokenizer.decode(tokens[:MAX_INPUT_TOKENS])\n",
    "            embeddings = await get_embedding(truncated_text)\n",
    "        else:\n",
    "            embeddings = await get_embedding(row.text)            \n",
    "        tags_embedding = await get_embedding(row.tags)\n",
    "        summary_embedding = await get_embedding(row.summary)\n",
    "        hyq_embedding = await get_embedding(row.hyq)\n",
    "        hyq_declarative_embedding = await get_embedding(row.hyq_declarative)\n",
    "        subtopics_embedding = await get_embedding(row.subtopics)\n",
    "    except Exception as e:\n",
    "        embeddings = None\n",
    "\n",
    "    df.loc[i, \"text_embedding\"] = str(embeddings) if embeddings else None\n",
    "    df.loc[i, \"summary_embedding\"] = str(summary_embedding)\n",
    "    df.loc[i, \"hyq_embedding\"] = str(hyq_embedding)\n",
    "    df.loc[i, \"hyq_declarative_embedding\"] = str(hyq_declarative_embedding)\n",
    "    df.loc[i, \"subtopics_embedding\"] = str(subtopics_embedding)\n",
    "    df.loc[i, \"tags_embedding\"] = str(tags_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6cc784",
   "metadata": {},
   "source": [
    "## WITH CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a251b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def chunk_text_uniform(text: str, tokenizer, max_tokens: int = MAX_INPUT_TOKENS, overlap: int = 128):\n",
    "    \"\"\"\n",
    "    Split text into evenly sized chunks, each up to max_tokens in length, with optional overlap.\n",
    "\n",
    "    :param text: The input text to split.\n",
    "    :param tokenizer: A tokenizer with encode/decode methods (e.g., from tiktoken or HuggingFace).\n",
    "    :param max_tokens: Maximum tokens allowed in each chunk.\n",
    "    :param overlap: Number of tokens to overlap between consecutive chunks.\n",
    "    :return: A generator yielding each chunk as a string.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    n_tokens = len(tokens)\n",
    "    \n",
    "    # If the text is within the limit, just yield it as one chunk\n",
    "    if n_tokens <= max_tokens:\n",
    "        yield tokenizer.decode(tokens)\n",
    "        return\n",
    "\n",
    "    # 1) Decide how many chunks we need, ignoring overlap for a moment\n",
    "    #    We subtract overlap to ensure we won't exceed max_tokens on each chunk\n",
    "    chunk_count = math.ceil(n_tokens / (max_tokens - overlap))\n",
    "\n",
    "    # 2) Compute an ideal chunk size so all chunks are about the same length\n",
    "    #    (some chunks might be smaller if n_tokens isn't divisible)\n",
    "    chunk_size = math.ceil(n_tokens / chunk_count)\n",
    "\n",
    "    # 3) Generate chunks in a sliding window with overlap\n",
    "    start = 0\n",
    "    for i in range(chunk_count):\n",
    "        end = min(start + chunk_size, n_tokens)\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        yield tokenizer.decode(chunk_tokens)\n",
    "\n",
    "        # Move start forward by chunk_size - overlap\n",
    "        # so we get the desired overlap on the next chunk\n",
    "        start += (chunk_size - overlap)\n",
    "        if start >= n_tokens:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33df4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def build_chunked_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    new_rows = []\n",
    "\n",
    "    for i, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "        # 1) Embed fields that are NOT chunked, only once\n",
    "        try:\n",
    "            tags_embedding = await get_embedding(row.tags)\n",
    "            summary_embedding = await get_embedding(row.summary)\n",
    "            hyq_embedding = await get_embedding(row.hyq)\n",
    "            hyq_declarative_embedding = await get_embedding(row.hyq_declarative)\n",
    "            subtopics_embedding = await get_embedding(row.subtopics)\n",
    "        except Exception as e:\n",
    "            # If embedding fails for these fields, skip or handle differently\n",
    "            tags_embedding = summary_embedding = hyq_embedding = None\n",
    "            hyq_declarative_embedding = subtopics_embedding = None\n",
    "\n",
    "        # 2) Handle chunking of 'text'\n",
    "        tokens = tokenizer.encode(row.text)\n",
    "        if len(tokens) <= MAX_INPUT_TOKENS:\n",
    "            # No need to chunk\n",
    "            chunked_texts = [row.text]\n",
    "        else:\n",
    "            # Chunk into uniform segments\n",
    "            chunked_texts = list(chunk_text_uniform(\n",
    "                row.text,\n",
    "                tokenizer\n",
    "            ))\n",
    "            \n",
    "        for chunk in chunked_texts:\n",
    "            try:\n",
    "                chunk_embedding = await get_embedding(chunk)\n",
    "            except:\n",
    "                chunk_embedding = None\n",
    "\n",
    "            # Create a new row for each chunk\n",
    "            new_rows.append({\n",
    "                **row.to_dict(),\n",
    "                \"text\": chunk,\n",
    "                \"text_embedding\": chunk_embedding,\n",
    "                \"tags_embedding\": tags_embedding,\n",
    "                \"summary_embedding\": summary_embedding,\n",
    "                \"hyq_embedding\": hyq_embedding,\n",
    "                \"hyq_declarative_embedding\": hyq_declarative_embedding,\n",
    "                \"subtopics_embedding\": subtopics_embedding\n",
    "            })\n",
    "\n",
    "    # Convert the collected rows into a new DataFrame\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5306c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 17:53:22,522 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:22,526 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:23,412 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:23,414 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:24,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:24,144 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:25,158 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:25,168 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:25,709 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:25,725 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:26,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:26,903 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "  8%|▊         | 1/13 [00:05<01:03,  5.30s/it]2025-03-18 17:53:27,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:27,502 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:28,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:28,341 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:28,766 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:28,769 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:30,563 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:30,567 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:31,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:31,068 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:33,045 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:33,047 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:33,731 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:33,733 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:34,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:34,315 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 15%|█▌        | 2/13 [00:12<01:11,  6.54s/it]2025-03-18 17:53:34,739 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:34,741 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:35,072 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:35,073 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:35,837 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:35,847 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:36,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:36,355 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:36,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:36,804 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:37,844 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:37,849 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:38,539 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:38,550 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 23%|██▎       | 3/13 [00:16<00:54,  5.49s/it]2025-03-18 17:53:39,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:39,348 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:39,755 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:39,767 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:40,174 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:40,181 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:40,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:40,662 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:41,014 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:41,016 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:41,652 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:41,653 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:42,274 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:42,290 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:42,897 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:42,902 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:43,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:43,335 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:43,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:43,931 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:44,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:44,501 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:45,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:45,162 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:46,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:46,017 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:46,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:46,494 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 31%|███       | 4/13 [00:24<00:58,  6.46s/it]2025-03-18 17:53:46,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:46,864 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:47,627 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:47,629 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:47,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:47,929 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:48,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:48,376 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:48,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:48,772 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:49,311 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:49,314 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:50,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:50,200 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:50,761 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:50,763 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:51,316 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:51,317 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:51,794 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:51,825 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:52,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:52,344 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:52,951 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:52,954 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:53,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:53,612 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 38%|███▊      | 5/13 [00:32<00:53,  6.70s/it]2025-03-18 17:53:55,226 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:55,228 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:55,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:56,062 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:56,361 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:56,363 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:56,878 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:56,914 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:57,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:57,552 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:57,868 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:57,869 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 46%|████▌     | 6/13 [00:36<00:41,  5.87s/it]2025-03-18 17:53:58,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:58,552 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:58,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:59,027 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:59,380 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:59,383 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:53:59,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:53:59,762 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:00,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:00,464 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:00,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:00,989 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:01,641 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:01,643 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:02,252 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:02,253 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:02,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:02,796 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:03,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:03,299 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:03,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:03,878 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:04,427 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:04,430 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:04,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:04,981 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:05,708 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:05,710 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:06,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:06,198 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 54%|█████▍    | 7/13 [00:44<00:40,  6.67s/it]2025-03-18 17:54:06,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:06,481 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:06,793 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:06,795 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:07,128 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:07,132 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:07,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:07,518 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:07,990 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:07,993 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:08,315 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:08,315 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 62%|██████▏   | 8/13 [00:46<00:26,  5.22s/it]2025-03-18 17:54:08,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:08,812 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:09,108 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:09,121 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:09,541 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:09,551 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:09,935 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:09,941 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:10,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:10,261 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:10,747 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:10,752 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:11,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:11,402 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:12,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:12,216 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:12,727 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:12,729 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:13,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:13,248 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:13,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:13,798 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:14,312 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:14,314 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:14,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:14,832 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:15,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:15,542 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 69%|██████▉   | 9/13 [00:53<00:23,  5.85s/it]2025-03-18 17:54:15,859 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:15,860 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:16,287 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:16,297 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:16,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:16,541 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:16,979 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:16,981 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:17,424 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:17,426 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:17,954 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:17,955 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:18,553 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:18,555 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:19,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:19,352 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 77%|███████▋  | 10/13 [00:57<00:15,  5.22s/it]2025-03-18 17:54:19,754 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:19,756 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:20,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:20,181 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:20,499 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:20,501 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:20,849 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:20,851 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:21,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:21,278 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:21,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:21,909 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:22,513 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:22,514 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:23,076 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:23,078 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 85%|████████▍ | 11/13 [01:01<00:09,  4.76s/it]2025-03-18 17:54:23,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:23,404 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:23,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:23,814 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:24,178 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:24,180 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:24,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:24,587 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:25,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:25,239 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:25,543 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:25,545 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      " 92%|█████████▏| 12/13 [01:03<00:04,  4.06s/it]2025-03-18 17:54:25,862 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:25,871 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:26,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:26,203 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:26,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:26,717 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:27,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:27,110 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:27,467 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:27,468 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:27,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:27,867 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "2025-03-18 17:54:28,443 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-03-18 17:54:28,445 - utils.embedding - INFO - Embedding successfull with model: text-embedding-3-small\n",
      "100%|██████████| 13/13 [01:06<00:00,  5.14s/it]\n"
     ]
    }
   ],
   "source": [
    "df_chunked = await build_chunked_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf10abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df. info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e398ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ebdd5-608b-4b19-ae18-ba863114e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e13112-f011-4244-b4ae-142abf1da90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c52d556-5024-4f82-a20d-bee050eee887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunked.to_csv(\"data/output/fedlex_EMBED.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae91376-2455-4690-a381-e1338341aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"indexing/data/zas_eak_copilot/akis/akis_EMBED_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea7e2-d443-45ea-9cd1-b9d7deeed80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
