from rag.prompts import OPENAI_RAG_SYSTEM_PROMPT_DE

from typing import List, Dict, Any
from dataclasses import asdict

from rag.models import RAGRequest, EmbeddingRequest
from rag.retrieval.factory import RetrieverFactory
from rag.retrieval.retrievers import RetrieverClient
from rag.llm.factory import LLMFactory
from rag.llm.base import BaseLLM

from sqlalchemy.orm import Session
from utils.embedding import get_embedding

from config.config import RAGConfig

# Setup logging
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RAGProcessor:
    """
    Class implementing the RAG process

    Parameters
    ----------
    llm : BaseLLM
    retriever_client : RetrieverClient
    """
    def __init__(self, llm: BaseLLM, retriever_client: RetrieverClient):

        self.llm_client = llm
        self.retriever_client = retriever_client

    def create_rag_message(self, context_docs: List[Any], query: str) -> List[Dict]:
        """
        Format the RAG message to send to the OpenAI API.

        Parameters
        ----------
        context_docs : str
            Context matching the query according to the retrieval process
        query : str
            User input question

        Returns
        -------
        list of dict
            Contains the message in the correct format to send to the OpenAI API

        """
        openai_rag_system_prompt = OPENAI_RAG_SYSTEM_PROMPT_DE.format(context_docs=context_docs, query=query)
        return [{"role": "system", "content": openai_rag_system_prompt},]

    def retrieve(self, db: Session, request: RAGRequest, language: str = None, tag: str = None):
        """
        Retrieve context documents related to the user input question.

        Parameters
        ----------
        db : Session
            Database session
        request : RAGRequest
            User input question
        language : str
            Question and context documents language
        tag : str
            Tag to filter the context documents
        k : int, default 0
            Number of context documents to return
        """
        rows = self.retriever_client.get_documents(db, request.query, language=language, tag=tag)
        logger.info(f"Retrieved {len(rows)} documents")

        return rows if len(rows) > 0 else [{"text": "", "url": ""}]

    def process(self, db: Session, request: RAGRequest, language: str = None, tag: str = None):
        """
        Process a RAGRequest to retrieve relevant documents and generate a response.

        This method retrieves relevant documents from the database, constructs a context from the documents, and then uses an LLM client to generate a response based on the request query and the context.

        Parameters
        ----------
        db : Session
            The database session to use for retrieving documents.
        request : RAGRequest
            The request to process.
        language : str, optional
            The language of the documents to retrieve. If not specified, documents in all languages are considered.
        tag : str, optional
            The tag to filter the documents to retrieve. If not specified, all documents are considered.

        Returns
        -------
        str
            The response generated by the LLM client.
        """
        documents = self.retrieve(db, request, language=language, tag=tag)
        logger.info(documents)
        context_docs = "\n\n".join([doc.text for doc in documents])  # TO UPDATE
        source_url = documents[0].url  # TO UPDATE

        messages = self.create_rag_message(context_docs, request.query)
        logger.info(messages)

        stream = self.llm_client.call(messages)

        return self.generate_stream(stream, source_url)

    async def embed(self, text_input: EmbeddingRequest):
        """
        Get the embedding of an embedding request.

        Parameters
        ----------
        text_input : EmbeddingRequest

        Returns
        -------
        dict
            The requested text embedding
        """
        embedding = get_embedding(text_input.text)
        return {"data": embedding}

    def generate_stream(self, stream, source_url):
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                yield chunk.choices[0].delta.content.encode("utf-8")
            else:
                # Send a special token indicating the end of the response
                yield f"\n\n<a href='{source_url}' target='_blank' class='source-link'>{source_url}</a>".encode("utf-8")
                return


llm_client = LLMFactory.get_llm_client(RAGConfig.LLM)
retrievers = RetrieverFactory.get_retriever_client(**asdict(RAGConfig.Retrieval))

processor = RAGProcessor(llm=llm_client,
                         retriever_client=retrievers)
